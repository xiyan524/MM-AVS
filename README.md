# MM-AVS: <u>M</u>ulti-<u>m</u>odal <u>A</u>rticle and <u>V</u>ideo <u>S</u>ummarization
A Full-Scale Dataset for Multi-modal Summarization


MM-AVS is a full-scale multimodal dataset comprehensively gathering documents, summaries, images, captions, videos, audios, transcripts, and titles in English from CNN and Daily Mail. To our best knowledge, this is the first collection that spans all modalities and nearly comprises all types of materials available in this community.


We're sharing them here for developers and researchers to explore, study, and learn from. 

## Preparation
Given the dataset is quite large, please download the demo firstly to make sure the dataset meets your requirement.

## Download
Download files include cnn.zip, dailymail.zip, train_id.txt and test_id.txt

**Method1: FTP**

ftp://45.77.122.178/pub/file_name (i.e., file_name->cnn.zip)

**Method2: Baidu Yun**

link：https://pan.baidu.com/s/1I7b18ddgvVvPmb3okaRzpQ 

password：uwbt 

Note: Videos are always limited by network disk, we recommend to method1. 

## Extension
The data scale is determined by its accompanied videos, considering this modality is more space-consuming than the other. The data acquirability code can be used for dataset extension.

## Citations

New papar is accepted as a short paper by NAACL2021. It is coming soon.

The original version can be found at ["Multi-modal Summarization for Video-containing Documents"](https://arxiv.org/abs/2009.08018).
